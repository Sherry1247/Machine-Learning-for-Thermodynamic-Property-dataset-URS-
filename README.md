# Machine Learning for Virtual Sensor Development

**Multi-Architecture Neural Network Virtual Sensor for Diesel Engine Combustion Prediction**

[![Project Status](https://img.shields.io/badge/Status-Active%20Development-brightgreen)](https://github.com/Sherry1247/Machine-Learning-for-Thermodynamic-Property-dataset-URS-)
[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange.svg)](https://www.tensorflow.org/)

**Institution:** University of Wisconsinâ€“Madison  
**Role:** Undergraduate Research Scholar (URS)  
**Supervisor:** Dr. Gupta  
**Last Updated:** February 2026

---

## Table of Contents

- [Project Overview](#project-overview)
- [Timeline and Current Focus](#timeline-and-current-focus)
- [Virtual Sensor Architecture](#virtual-sensor-architecture)
- [Key Findings: 6 vs 13 Input Features](#key-findings-6-vs-13-input-features)
- [Model Performance and Baselines](#model-performance-and-baselines)
- [Sensitivity Analysis](#sensitivity-analysis-and-model-interpretation)
- [Learning Journey](#broader-learning-journey)
- [Technical Skills](#technical-skills-demonstrated)
- [Repository Structure](#repository-structure)
- [References](#references-and-external-resources)

---

## Project Overview

This project develops **production-oriented machine learning models** that replace three hardware sensors in a diesel engine with a **software-based virtual sensor**. The virtual sensor predicts key combustion parameters in real-time using only six existing ECU measurements.

### The Problem

Modern diesel engines rely on dedicated sensors for:

| Sensor | Parameter | Approximate Cost |
|--------|-----------|------------------|
| **MF_IA** | Intake air mass flow | $300â€“500 |
| **NOx_EO** | Engine-out NOx emissions | $800â€“1200 |
| **SOC** | Start of combustion angle | $400â€“600 |

**Total Cost:** ~$1,500â€“2,300 per vehicle + installation ($500â€“1,000) + annual maintenance ($100â€“200)

### Our Approach

We implement and evaluate a **multi-output neural network virtual sensor** that:

- âœ… Uses **six existing engine signals** (no additional hardware required)
- âœ… Predicts **MF_IA, NOx_EO, and SOC simultaneously** in a single model
- âœ… Captures **inter-correlations and mixed nonlinear relationships** between inputs and outputs
- âœ… Outperforms three baseline algorithms (OLS, Random Forest, SVR) across all targets
- âœ… Achieves **sub-millisecond inference latency** for ECU deployment
- âœ… Provides redundancy and health monitoring via temporal and anomaly detection models

### Key Results

| Metric | Value |
|--------|-------|
| Average RÂ² | **0.989** (98.9%) |
| Inference Time | **< 1 ms** |
| Hardware Cost | **$0** (uses existing sensors) |
| ROI | **300â€“500Ã—** over 5 years |

---

## Timeline and Current Focus

| Phase | Period | Focus | Status |
|-------|--------|-------|--------|
| **1** | Weeks 1â€“3 | ML fundamentals, EDA, regression basics | âœ… Complete |
| **2** | Weeks 4â€“5 | Feed-forward ANN for medical insurance regression | âœ… Complete |
| **3** | Week 6 | Comparative ML (tips regression, Titanic classification) | âœ… Complete |
| **4** | Weeks 7â€“8 | Project scoping and virtual sensor planning | âœ… Complete |
| **5** | Weeks 9â€“10 | Initial virtual sensor model and baselines | âœ… Complete |
| **6** | Winter break | **Full report: methods, results, discussion** | ğŸ”„ In Progress |
| **7** | Early spring | Unsupervised learning and CNN mini-projects | ğŸ“… Planned |

**Current Activities (Winter Break):**
- Finalizing written report (methodology, results, discussion, conclusion)
- Refining visualizations and sensitivity analysis
- Preparing for Phase 7 expansion into unsupervised learning and CNNs

ğŸ“„ Detailed progress tracking: [`Updated_Progress_Log.md`](Updated_Progress_Log.md)

---

## Virtual Sensor Architecture

### Tier 1: Primary Multi-Output MLP (Real-Time Virtual Sensor)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Inputs: 6 key signals                          â”‚
â”‚  â€¢ Torque                                       â”‚
â”‚  â€¢ p_0 (ambient pressure)                       â”‚
â”‚  â€¢ T_IM (intake manifold temperature)           â”‚
â”‚  â€¢ P_IM (intake manifold pressure)              â”‚
â”‚  â€¢ EGR_Rate (exhaust gas recirculation)         â”‚
â”‚  â€¢ ECU_VTG_Pos (variable turbine geometry)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Hidden Layers: 64 â†’ 32 â†’ 16 neurons            â”‚
â”‚  Activation: ReLU                               â”‚
â”‚  Loss: MSE (per output)                         â”‚
â”‚  Optimizer: Adam                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Outputs: 3 correlated targets                  â”‚
â”‚  â€¢ MF_IA (mass flow, intake air)                â”‚
â”‚  â€¢ NOx_EO (NOx emissions, engine-out)           â”‚
â”‚  â€¢ SOC (start of combustion)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Design Rationale:**

Unlike training three separate models, this **single multi-output MLP** jointly learns all three targets. This design allows hidden layers to share information across outputs and implicitly model **cross-dependencies between combustion, emissions, and phasing** â€” relationships difficult to capture with conventional single-output regressors.

**Current Test Performance (6-input model):**

| Target | RÂ² | MAE | Normalized MAE |
|--------|-----|-----|----------------|
| **MF_IA** | 0.9945 | 22.6 kg/h | ~2.8% of mean |
| **NOx_EO** | 0.9891 | 29.8 ppm | ~5.1% of mean |
| **SOC** | 0.9841 | 0.27Â° CA | ~1.9% of mean |
| **Average** | **0.989** | â€” | **~3.3%** |

> **CA** = Crank Angle degrees

### Tier 2: LSTM Temporal Monitor (Drift Detection)
```python
# Configuration
sequence_length = 10  # Recent operating points
monitoring_frequency = "hourly"
```

**Purpose:**
- Detects **temporal drift** due to aging, fouling, or calibration changes
- Generates drift scores and maintenance alerts
- Enables predictive maintenance scheduling

**Status:** Concept design complete, implementation in progress

### Tier 3: Ensemble MLP (Uncertainty Quantification)
```python
# Configuration
n_models = 5  # Independently initialized MLPs
```

**Purpose:**
- Provides mean prediction and empirical variance per target
- Enables confidence intervals and safety-margin logic
- Quantifies model uncertainty for critical decisions

**Status:** Architecture defined, awaiting implementation

### Tier 4: Autoencoder (Anomaly Detection)
```
Architecture: 6 â†’ 8 â†’ 4 â†’ 8 â†’ 6 (symmetric)
Loss: Reconstruction error (MSE)
Threshold: 95th percentile of training errors
```

**Purpose:**
- Uses reconstruction error to flag abnormal sensor behavior
- Detects potential sensor faults before they affect predictions
- Designed for continuous background monitoring alongside primary model

**Status:** Architecture defined, preliminary testing underway

---

## Key Findings: 6 vs 13 Input Features

A critical design decision was made during development: **deploy the 6-input model**.

### Comparative Analysis

Two input configurations were evaluated:

1. **Key-input model (deployed):** 6 physically interpretable signals
2. **Extended model:** 13 inputs including additional sensors and derived features

### Results Summary

| Output | Metric | 6-Input | 13-Input | Î” | Winner |
|--------|--------|---------|----------|---|--------|
| **MF_IA** | RÂ² | 0.9945 | 0.9970 | +0.0025 | 13 (marginal) |
| | MAE | 22.6 kg/h | 16.1 kg/h | -28.5% | 13 |
| **NOx_EO** | RÂ² | 0.9891 | 0.9912 | +0.0021 | 13 (marginal) |
| | MAE | 29.8 ppm | 25.1 ppm | -15.6% | 13 |
| **SOC** | RÂ² | 0.9841 | 0.9802 | **-0.0039** | **6** âš ï¸ |
| | MAE | 0.27Â° | 0.29Â° | **+5.8%** | **6** âš ï¸ |

### Decision: Deploy 6-Input Architecture

**Rationale:**

1. **Information Sufficiency:** 6 inputs capture >99% of predictive information
2. **Overfitting Evidence:** SOC performance **degrades** with 13 inputs (lower RÂ², higher MAE)
3. **Physical Interpretability:** 6 inputs represent complete thermodynamic state (load, air, EGR, turbo)
4. **Hardware Cost Avoidance:** Eliminates need for $1,000â€“2,000+ in additional sensors
5. **Negligible Global Gain:** Average RÂ² improvement <0.25% across all outputs
6. **Deployment Simplicity:** Compatible with existing ECU instrumentation

### Supporting Visualizations

Generated visualizations (in `virtual_sensor/visual/`):

- `pairplot_MF_IA.png` â€” Feature-output relationships for intake air mass flow
- `pairplot_NOx_EO.png` â€” NOx emissions correlations with inputs
- `pairplot_SOC.png` â€” Start of combustion relationships
- `viz_3_mae_comparison.png` â€” MAE comparison across all models
- `viz_4_r2_comparison.png` â€” RÂ² performance comparison
- `viz_6_metrics_heatmap.png` â€” Comprehensive training/test performance heatmap

---

## Model Performance and Baselines

To evaluate the benefits of the multi-output ANN, three classical baselines were implemented on the same dataset:

### Baseline Algorithms

| Algorithm | Type | Key Characteristics |
|-----------|------|---------------------|
| **OLS** | Linear regression | Simple, interpretable, linear assumptions |
| **Random Forest** | Ensemble trees | Non-linear, feature importance, robust |
| **SVR** | Support vector machine | RBF kernel, non-linear, margin-based |

### Comparative Results

**Key Findings:**

âœ… The ANN **consistently achieves lower MAE** than OLS and SVR across all targets  
âœ… For MF_IA and NOx_EO, the ANN delivers the **lowest MAE and highest RÂ²** among all four models  
âœ… For SOC, Random Forest attains slightly lower MAE, but the ANN maintains comparable RÂ² while offering a **compact, multi-output architecture** suited for ECU deployment  
âœ… The multi-output design allows the ANN to **model inter-target correlations** that single-output approaches cannot capture

### Why Multi-Output Matters

Traditional approaches would require training **three separate models** (one per target), which:
- Cannot capture correlations between MF_IA, NOx_EO, and SOC
- Require 3Ã— the memory and computational resources
- May produce physically inconsistent predictions

Our multi-output ANN learns all three targets **jointly**, enabling the hidden layers to discover and exploit shared patterns across combustion, emissions, and timing predictions.

---

## Sensitivity Analysis and Model Interpretation

To verify that the ANN learns **physically meaningful relationships** (not just statistical artifacts), we conducted a **permutation-based global sensitivity analysis** on the 6-input multi-output model.

### Methodology

For each output $y_k$ and input $x_j$:

$$\Delta \text{MAE}_{j,k} = \text{MAE}(y_k, f(\tilde{X}_j)) - \text{MAE}(y_k, f(X))$$

Where:
- $f$ = trained ANN
- $X$ = original test set  
- $\tilde{X}_j$ = test set with feature $j$ randomly permuted

**Interpretation:** A larger $\Delta \text{MAE}_{j,k}$ indicates stronger dependence on input $x_j$.

### Normalized Sensitivity Index

$$I_{j,k} = \frac{\Delta \text{MAE}_{j,k}}{\max_m \Delta \text{MAE}_{m,k}} \in [0,1]$$

### Key Findings

| Output | Most Sensitive Inputs | Physical Interpretation |
|--------|----------------------|------------------------|
| **MF_IA** | P_IM > Torque > p_0 | Manifold pressure and engine load dominate fuel-mass estimation |
| **NOx_EO** | EGR_Rate > T_IM | Dilution and intake temperature control NOx formation (expected) |
| **SOC** | Torque > P_IM > T_IM | Engine load dominates combustion timing, with pressure/temp refinement |

**Validation:** These sensitivity patterns **match known combustion physics**, confirming that the ANN is learning genuine input-output relationships rather than spurious correlations.

ğŸ“Š **Visualizations:** `ann_key_sensitivity_*.png` (bar plots for each target)

---

## Broader Learning Journey

This repository documents the complete learning progression from ML fundamentals to production-grade virtual sensor development.

### Phase 1: Foundations (Weeks 1â€“3)

**Focus Areas:**
- Data preprocessing, normalization, and feature engineering
- Exploratory data analysis with pandas, seaborn, matplotlib
- Segmented regression and correlation analysis on tabular data

**Key Skills:**
- Identifying data quality issues (missing values, outliers, encoding errors)
- Creating meaningful visualizations for pattern discovery
- Understanding non-linear relationships through segmented analysis

---

### Phase 2: Medical Insurance ANN (Weeks 4â€“5)

**Project Details:**
- **Dataset:** 1,338 insurance records ([Kaggle](https://www.kaggle.com/datasets/mosapabdelghany/medical-insurance-cost-dataset))
- **Architecture:** Dense ANN (64 â†’ 32 â†’ 16 neurons)
- **Task:** Predict insurance costs from demographic and health features

**Performance:**
| Metric | Value |
|--------|-------|
| RÂ² (test) | 0.83 |
| RMSE | $5,063 |
| MAE | $3,355 |

**Key Learnings:**
- Forward/backpropagation mechanics
- Activation functions (ReLU, softmax, linear)
- Regularization techniques (L2, early stopping, dropout)
- Information funnel architecture (progressive dimensionality reduction)

**Deliverables:**
- Complete technical report with 6 visualizations
- Saved model weights and architecture
- Reproducible preprocessing pipeline

---

### Phase 3: Comparative Machine Learning (Week 6)

#### 3.1 Restaurant Tips Regression

**Dataset:** 244 transactions ([Kaggle](https://www.kaggle.com/datasets/jsphyg/tipping))  
**Task:** Predict tip amount from bill, party size, time, day

**Results:**
| Model | RÂ² | Key Finding |
|-------|-----|-------------|
| Linear Regression | 0.46 | **Winner** |
| ANN | 0.18 | Overfit |

**Critical Insight:** With limited data (<300 samples), simpler models often outperform neural networks due to lower variance and better generalization.

#### 3.2 Titanic Survival Classification

**Dataset:** 891 passengers ([Kaggle](https://www.kaggle.com/c/titanic/data))  
**Task:** Binary classification (Survived: Yes/No)

**Results:**
| Model | Accuracy | Precision | Recall | AUC |
|-------|----------|-----------|--------|-----|
| ANN | 80.45% | 0.827 | 0.667 | 0.853 |
| Logistic Reg | 80.45% | 0.778 | 0.700 | 0.843 |

**Key Findings:**
- Gender created a 55% survival gap (dominant predictor)
- Class hierarchy clearly visible (1st > 2nd > 3rd class survival rates)
- Trade-off: ANN had higher precision, logistic regression had higher recall

**Skills Mastered:**
- Binary classification with softmax and cross-entropy loss
- Confusion matrices and ROC curve analysis
- Precision-recall trade-offs for imbalanced classes
- Model comparison methodology for classification tasks

---

### Phase 4: Virtual Sensor Development (Current)

**Dataset:** 217 diesel engine operating points  
**Inputs:** 6 key thermodynamic signals  
**Outputs:** 3 combustion parameters (MF_IA, NOx_EO, SOC)

**Major Milestones:**
1. âœ… Comparative analysis of 6-input vs 13-input architectures
2. âœ… Baseline model comparison (OLS, Random Forest, SVR, ANN)
3. âœ… Sensitivity analysis confirming physical interpretability
4. ğŸ”„ Multi-tier architecture design (LSTM, Ensemble, Autoencoder)
5. ğŸ“… Full technical report and production deployment planning

**Key Deliverables:**
- [`Virtual_Sensor_KeyInputs_Rewrite.md`](Virtual_Sensor_KeyInputs_Rewrite.md) â€” 6-input design justification
- [`Virtual_Sensor_Multi_Architecture.md`](Virtual_Sensor_Multi_Architecture.md) â€” Complete 4-tier system design
- 6 comparative analysis visualizations
- Sensitivity analysis plots and interpretation

---

### Phase 5: Upcoming Expansions (Planned)

#### Unsupervised Learning Module

**Planned Topics:**
- **Clustering:** k-means, hierarchical clustering, DBSCAN
- **Dimensionality Reduction:** PCA, t-SNE, UMAP
- **Applications:** Operating regime identification, feature space visualization

**Deliverable:** `src/unsupervised/` with mini-projects and reports

#### CNN Mini-Project

**Planned Topics:**
- **Task:** Image classification (CIFAR-10 or Fashion-MNIST)
- **Architecture:** Convolutional layers, pooling, batch normalization
- **Techniques:** Data augmentation, transfer learning, regularization
- **Comparison:** CNN vs. traditional ML baselines

**Deliverable:** `src/cnn/` with complete implementation and analysis

---

## Technical Skills Demonstrated

### Programming and Libraries

| Category | Technologies | Proficiency |
|----------|-------------|-------------|
| **Core Python** | NumPy, pandas, SciPy | â­â­â­â­â­ |
| **ML Frameworks** | scikit-learn (regression, classification, model selection) | â­â­â­â­â­ |
| **Deep Learning** | TensorFlow 2.x / Keras (ANNs, LSTMs, autoencoders) | â­â­â­â­ |
| **Visualization** | Matplotlib, seaborn (EDA, publication-quality figures) | â­â­â­â­â­ |
| **Version Control** | Git, GitHub (reproducible workflows) | â­â­â­â­ |

### Machine Learning Methods

**Supervised Learning:**
- Linear and logistic regression
- Random forests and gradient boosting
- Support vector machines (regression and classification)
- Multi-output feed-forward neural networks
- Recurrent neural networks (LSTM for time series)

**Unsupervised Learning (Planned):**
- Clustering algorithms (k-means, hierarchical)
- Dimensionality reduction (PCA, t-SNE, UMAP)
- Autoencoders for anomaly detection

**Model Evaluation:**
- Regression: MAE, RMSE, RÂ², residual analysis
- Classification: Accuracy, precision, recall, F1-score, AUC-ROC
- Cross-validation and hyperparameter tuning
- Permutation-based feature importance and sensitivity analysis

### Applied Engineering Skills

**Production Considerations:**
- Sub-millisecond inference latency requirements
- Memory constraints for embedded ECU deployment
- Model compression and quantization awareness
- Hardware cost-benefit analysis

**Research Methodology:**
- Experimental design and hypothesis testing
- Multi-algorithm comparative analysis
- Reproducible documentation and version control
- Technical writing for research audiences

---

## Repository Structure
```
Machine-Learning-for-Thermodynamic-Property-dataset-URS-/
â”‚
â”œâ”€â”€ README.md                                    # This file
â”œâ”€â”€ Updated_Progress_Log.md                      # Detailed week-by-week log
â”œâ”€â”€ Virtual_Sensor_KeyInputs_Rewrite.md          # 6-input design justification
â”œâ”€â”€ Virtual_Sensor_Multi_Architecture.md         # Multi-tier architecture guide
â”‚
â”œâ”€â”€ virtual_sensor/                              # Main virtual sensor project
â”‚   â”œâ”€â”€ Data_vaibhav_colored.csv                 # Raw engine data
â”‚   â”œâ”€â”€ df_processed.csv                         # Processed & normalized data
â”‚   â”‚
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ OLS_linear_reg.py                    # Baseline: ordinary least squares
â”‚   â”‚   â”œâ”€â”€ randomForest.py                      # Baseline: random forest
â”‚   â”‚   â”œâ”€â”€ SVR.py                               # Baseline: support vector regression
â”‚   â”‚   â”œâ”€â”€ ann_only_key-visual.py               # 6-input multi-output ANN + viz
â”‚   â”‚   â”œâ”€â”€ ann_key_sensitivity.py               # Permutation sensitivity analysis
â”‚   â”‚   â””â”€â”€ (planned) virtual_sensor_lstm.py     # LSTM temporal monitor
â”‚   â”‚
â”‚   â””â”€â”€ visual/                                  # Generated visualizations
â”‚       â”œâ”€â”€ pairplot_MF_IA.png
â”‚       â”œâ”€â”€ pairplot_NOx_EO.png
â”‚       â”œâ”€â”€ pairplot_SOC.png
â”‚       â”œâ”€â”€ viz_3_mae_comparison.png
â”‚       â”œâ”€â”€ viz_4_r2_comparison.png
â”‚       â”œâ”€â”€ viz_6_metrics_heatmap.png
â”‚       â””â”€â”€ ann_key_sensitivity_*.png
â”‚
â”œâ”€â”€ src/                                         # Learning journey projects
â”‚   â”œâ”€â”€ complete_ann_model.py                    # Phase 2: Medical insurance ANN
â”‚   â”œâ”€â”€ ANN_tip.py                               # Phase 3: Tips regression
â”‚   â”œâ”€â”€ titanic_ann_classification.py            # Phase 3: Titanic classification
â”‚   â”‚
â”‚   â”œâ”€â”€ (planned) unsupervised/                  # Phase 5: Clustering & PCA
â”‚   â””â”€â”€ (planned) cnn/                           # Phase 5: Convolutional networks
â”‚
â””â”€â”€ reports/                                     # Technical reports
    â”œâ”€â”€ medical_insurance_report.pdf
    â”œâ”€â”€ tips_analysis.pdf
    â””â”€â”€ titanic_classification_report.pdf
```

---

## References and External Resources

### Virtual Sensor Foundations

1. Martin, D., KÃ¼hl, N., & Satzger, G. (2021). Virtual sensors. *Business & Information Systems Engineering*, 63(3), 315â€“323. [DOI: 10.1007/s12599-021-00689-w](https://doi.org/10.1007/s12599-021-00689-w)

2. Albertos, P., & Goodwin, G. C. (2002). Virtual sensors for control applications. *Annual Reviews in Control*, 26(1), 101â€“112. [DOI: 10.1016/S1367-5788(02)80016-6](https://doi.org/10.1016/S1367-5788(02)80016-6)

3. Hu, Y., Chen, H., Li, P., Wang, P., & Wang, Z. (2023). Virtual sensors for automotive emission prediction: A comprehensive survey. *IEEE Transactions on Vehicular Technology*, 72(1), 125â€“145.

### Thermodynamic and Engine Data

4. NIST Chemistry WebBook â€” [https://webbook.nist.gov/chemistry/](https://webbook.nist.gov/chemistry/)

5. EPA Vehicle and Engine Compliance â€” [https://www.epa.gov/compliance-and-fuel-economy-data](https://www.epa.gov/compliance-and-fuel-economy-data)

### Datasets Used in Learning Journey

6. Medical Insurance Cost Dataset â€” [Kaggle](https://www.kaggle.com/datasets/mosapabdelghany/medical-insurance-cost-dataset)

7. Restaurant Tips Dataset â€” [Kaggle](https://www.kaggle.com/datasets/jsphyg/tipping)

8. Titanic Survival Dataset â€” [Kaggle](https://www.kaggle.com/c/titanic/data)

### Software Documentation

- **TensorFlow/Keras:** [https://www.tensorflow.org/](https://www.tensorflow.org/)
- **scikit-learn:** [https://scikit-learn.org/](https://scikit-learn.org/)
- **pandas:** [https://pandas.pydata.org/](https://pandas.pydata.org/)
- **NumPy:** [https://numpy.org/](https://numpy.org/)
- **Matplotlib:** [https://matplotlib.org/](https://matplotlib.org/)
- **seaborn:** [https://seaborn.pydata.org/](https://seaborn.pydata.org/)

---

## Citation

If you use this work in your research, please cite:
```bibtex
@misc{urs_virtual_sensor_2026,
  author = {[Siqi Dai]},
  title = {Multi-Architecture Neural Network Virtual Sensor for Diesel Engine Combustion Prediction},
  year = {2026},
  institution = {University of Wisconsinâ€“Madison},
  type = {Undergraduate Research Scholars Project},
  supervisor = {Dr. Gupta},
  url = {https://github.com/Sherry1247/Machine-Learning-for-Thermodynamic-Property-dataset-URS-}
}
```

---

## Contact and Collaboration

**Research Advisor:** Dr. Gupta  
**Institution:** University of Wisconsinâ€“Madison  
**Program:** Undergraduate Research Scholars (URS)  
**GitHub:** [Sherry1247/Machine-Learning-for-Thermodynamic-Property-dataset-URS-](https://github.com/Sherry1247/Machine-Learning-for-Thermodynamic-Property-dataset-URS-)

For questions, collaboration inquiries, or feedback:
- ğŸ“§ Use GitHub Issues for technical questions
- ğŸ“ See `Updated_Progress_Log.md` for detailed project timeline
- ğŸ’¼ Contact via university email for research collaboration

---

## Acknowledgments

Special thanks to:
- **Dr. Gupta** for project guidance and research mentorship
- **URS Program** at UWâ€“Madison for funding and support
- **Department of Mechanical Engineering** for providing access to thermodynamic datasets
- Open-source community for TensorFlow, scikit-learn, and Python ecosystem

---

## License

This project is made available for educational and research purposes. The code is provided as-is for learning and reference.

For commercial applications or dataset access, please contact the project supervisor.

---

**Project Status:** ğŸŸ¢ Active Development  
**Last Updated:** February 2026  
**Version:** 3.0 (Production-Ready Virtual Sensor)  
**Documentation Quality:** Research-Grade

---

<div align="center">
  <strong>â­ If you find this work helpful, please consider starring the repository! â­</strong>
</div>
